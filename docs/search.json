[{"path":"index.html","id":"preliminary-information","chapter":"Preliminary Information","heading":"Preliminary Information","text":"artificial book demonstrate look RapidBook Template, template rapidly deploy either Python R based books using Bookdown.uses R Markdown, Python must used reticulate interface.","code":""},{"path":"introduction-to-r.html","id":"introduction-to-r","chapter":"1 Introduction to R","heading":"1 Introduction to R","text":"section covers basics getting started R, beginning \nnotes installation continuing basics interacting R command line.beginning R, must installed usage. R available \nsource code CRAN, Comprehensive R Network. \nNonetheless, users probably install R distributed binary. also available CRAN. example, Microsoft Windows binary distributed self-extracting .exe file. Simply download file install \ndownload.\nMicrosoft Windows users, standard installation create desktop icon start menu item opening R.","code":""},{"path":"introduction-to-r.html","id":"rs-command-line","chapter":"1 Introduction to R","heading":"1.1 R’s command line","text":"several ways interact R, us primary one command line, also known console. command line RStudio console pane. \ncommand line common R’s interactive interfaces. name comes place one types commands.\nfigure typed command “2 + 2” pressed return key send command R’s interpreter. responded answer 4, prefixed [1], make sense talk data vectors Chapter 2.\ntext, rather show screenshots RStudio console, typeset command line. “2 + 2” command look like:Whereas, average five numbers might look like:can tell R add two sets numbers together. add \nfirst number x first number y, . However, x \ny length. can check length using length function, follows:","code":"\n2 + 2## [1] 4\n(1 + 3 + 2 + 12 + 8)/5## [1] 5.2\nx <- c(1L, 6L, 2L) # Defining an atomic vector of integers\nlength(x)## [1] 3"},{"path":"introduction-to-r.html","id":"r-base-graphics","chapter":"1 Introduction to R","heading":"1.2 R Base Graphics","text":"plot function primary way plot data R. instance,plot(x, y) produces scatterplot numbers x versus numbers y. \nmany additional options can passed plot() function. example, passing argument xlab result label x-axis. find information plot() function, type ?plot command line.","code":"\nx <- rnorm(100) \ny <- rnorm(100)\n\nplot(x,y)"},{"path":"descriptive-statistics.html","id":"descriptive-statistics","chapter":"2 Descriptive Statistics","heading":"2 Descriptive Statistics","text":"Descriptive statistics used describe basic features data study. provide simple summaries sample measures. Together simple graphics analysis, form basis virtually every quantitative analysis data.Descriptive statistics typically distinguished inferential statistics. descriptive statistics simply describing data shows. inferential statistics, trying reach conclusions extend beyond immediate data alone. instance, use inferential statistics try infer sample data population might think. , use inferential statistics make judgments probability observed difference groups dependable one one might happened chance study. Thus, use inferential statistics make inferences data general conditions; use descriptive statistics simply describe ’s going data.","code":""},{"path":"descriptive-statistics.html","id":"summary-statistics-in-r","chapter":"2 Descriptive Statistics","heading":"2.1 Summary Statistics in R","text":"’ll use dataset iris throughout example. dataset imported default R, need load running iris command line.\n, load iris dataset rename df","code":"\ndf <- iris # This is a common name for a single data frame"},{"path":"descriptive-statistics.html","id":"preview","chapter":"2 Descriptive Statistics","heading":"2.1.1 Preview","text":", preview dataset:","code":"\nhead(df) # first 6 observations##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n## 1          5.1         3.5          1.4         0.2  setosa\n## 2          4.9         3.0          1.4         0.2  setosa\n## 3          4.7         3.2          1.3         0.2  setosa\n## 4          4.6         3.1          1.5         0.2  setosa\n## 5          5.0         3.6          1.4         0.2  setosa\n## 6          5.4         3.9          1.7         0.4  setosa"},{"path":"descriptive-statistics.html","id":"data-frame-structure","chapter":"2 Descriptive Statistics","heading":"2.1.2 Data Frame Structure","text":", preview dataset’s structure:","code":"\nstr(df) # structure of a dataset## 'data.frame':    150 obs. of  5 variables:\n##  $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n##  $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n##  $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n##  $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n##  $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ..."},{"path":"descriptive-statistics.html","id":"summary","chapter":"2 Descriptive Statistics","heading":"2.1.3 Summary","text":"get summary statistics column, can use summary function.","code":"\nsummary(df)##   Sepal.Length    Sepal.Width     Petal.Length    Petal.Width          Species  \n##  Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100   setosa    :50  \n##  1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300   versicolor:50  \n##  Median :5.800   Median :3.000   Median :4.350   Median :1.300   virginica :50  \n##  Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199                  \n##  3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800                  \n##  Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500"},{"path":"descriptive-statistics.html","id":"plots","chapter":"2 Descriptive Statistics","heading":"2.2 Plots","text":"section, going use Hadley Wickham’s ggplot2 package, widely adopted library plotting R.  uses approach plotting heavily inspired Leland Wilkinson’s Grammar Graphics.","code":""},{"path":"descriptive-statistics.html","id":"bar-chart","chapter":"2 Descriptive Statistics","heading":"2.2.1 Bar Chart","text":"","code":"\nggplot(data = df,\n       mapping = aes(x = Species,\n                     fill = Species)) +\n  geom_bar()"},{"path":"descriptive-statistics.html","id":"histogram","chapter":"2 Descriptive Statistics","heading":"2.3 Histogram","text":"","code":"\nggplot(data = df,\n       mapping = aes(x = Sepal.Length)) +\n  geom_histogram() +\n  labs(\n    title = \"Histogram of Sepal Length\",\n    x = \"Sepal Length\"\n  )## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`."},{"path":"descriptive-statistics.html","id":"density-function","chapter":"2 Descriptive Statistics","heading":"2.3.1 Density Function","text":"","code":"\nggplot(data = df,\n       mapping = aes(x = Sepal.Length)) +\n  geom_density(fill = \"red\",\n               col = \"red\",\n               alpha = .5) +\n  labs(\n    title = \"Density of Sepal Length\",\n    x = \"Sepal Length\",\n    y = \"Probability\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = .5,\n                              face = \"bold\")\n  )"},{"path":"descriptive-statistics.html","id":"scatterplot","chapter":"2 Descriptive Statistics","heading":"2.3.2 Scatterplot","text":"","code":"\nggplot(data = df,\n       mapping = aes(x = Sepal.Length,\n                     y = Petal.Width,\n                     col = Petal.Width)) +\n  geom_point() +\n  guides(col = \"none\")"},{"path":"descriptive-statistics.html","id":"jitter-plot","chapter":"2 Descriptive Statistics","heading":"2.3.3 Jitter Plot","text":"Jitter plot simply scatterplot certain offset.","code":"\nggplot(data = df,\n       mapping = aes(x = Sepal.Length,\n                     y = Petal.Width,\n                     col = Petal.Width)) +\n  geom_jitter() + #scatterplot with offset\n  guides(col = \"none\")"},{"path":"descriptive-statistics.html","id":"regression-line","chapter":"2 Descriptive Statistics","heading":"2.3.4 Regression Line","text":"can add regression line last jitter plot adding call geom_smooth, :’s also couple things can , just template.","code":"\nggplot(data = df,\n       mapping = aes(x = Sepal.Length,\n                     y = Petal.Width,\n                     col = Petal.Width)) +\n  geom_jitter() +\n  geom_smooth(method = \"lm\",\n              formula = y ~ x) + ## Simple Linear Regression, regressing y over x\n  guides(col = \"none\")## Warning: The following aesthetics were dropped during statistical transformation: colour.\n## ℹ This can happen when ggplot fails to infer the correct grouping structure in the data.\n## ℹ Did you forget to specify a `group` aesthetic or to convert a numerical variable into a factor?"},{"path":"linear-regression.html","id":"linear-regression","chapter":"3 Linear Regression","heading":"3 Linear Regression","text":"","code":""},{"path":"linear-regression.html","id":"definition","chapter":"3 Linear Regression","heading":"3.1 Definition","text":"Suppose random sample size \\(n\\) drawn population, measurements \\((x_{i1}, x_{i2}, \\dots, x_{ik}, y_i)\\), \\(= 1, \\dots, n\\), obtained \\(n\\) individuals.random variables \\(x_{i1}, x_{i2}, \\dots, x_{ik}\\) commonly termed predictor variables (simply, predictors). Depending field application, may also called independent variables, regressors, features, covariates, explanatory variables.\\(y_i\\) variable called response variable (simply, response). terms include target variable, variate, dependent variable, outcome variable.Linear Regression Model represents relation response variable \\(y\\) predictor variables \\(x_1, x_2, \\dots, x_k\\) (lowercase notation simplicity), form:\\[\ny = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_k x_k + \\epsilon\n\\]\\(\\beta_0, ..., \\beta_k\\) constants regression coefficients, \\(\\epsilon\\) random error term follows normal distribution mean zero (\\(\\mu = 0\\)) constant variance \\(\\sigma^2\\). , \\(\\epsilon \\sim Norm(\\mu = 0, \\sigma^2)\\). Also, random errors assumed independent different individuals sample.parameters model \\(\\beta_0, ..., \\beta_k\\), variance \\(\\sigma^2\\) unknown estimated sample data.Note relationship predictors response necessarily linear, polynomial interaction terms may included, necessarily linear beta coefficients. , relationship modeled linear combination parameters.Note , general linear regression model, response variable y normal distribution mean:\\[\n\\begin{align}\n\\mathbb{E}(y|x) = \\beta_0 + \\beta_1 \\cdot x_1 + ... + \\beta_k \\cdot x_k\n\\end{align}\n\\]","code":""},{"path":"linear-regression.html","id":"simple-linear-regression","chapter":"3 Linear Regression","heading":"3.2 Simple Linear Regression","text":"Simple linear regression simplification Linear Regression Model estimates relationship one independent variable one dependent variable using straight line. variables quantitative.example, ’ll use Boston dataset, contains 506 census tracts Boston. seek predict medv, median house value, using lstat predictor, represents percent households low socioeconomic status.start using lm function fit simple linear regression model, medv response lstat predictor. basic syntax lm(y ∼ x, data), y response, x predictor, data data set (usually dataframe) two variables kept.type name variable, case linear_reg basic information model output.detailed information, use summary(linear_reg). gives us p-values standard errors coefficients, well \\(R^2\\) statistic \\(F\\)-statistic model.can also plot linear regression line using ggplot2:","code":"\ndf <- read.csv(\"./datasets/Boston.csv\")\nhead(df)##      crim zn indus chas   nox    rm  age    dis rad tax ptratio lstat medv\n## 1 0.00632 18  2.31    0 0.538 6.575 65.2 4.0900   1 296    15.3  4.98 24.0\n## 2 0.02731  0  7.07    0 0.469 6.421 78.9 4.9671   2 242    17.8  9.14 21.6\n## 3 0.02729  0  7.07    0 0.469 7.185 61.1 4.9671   2 242    17.8  4.03 34.7\n## 4 0.03237  0  2.18    0 0.458 6.998 45.8 6.0622   3 222    18.7  2.94 33.4\n## 5 0.06905  0  2.18    0 0.458 7.147 54.2 6.0622   3 222    18.7  5.33 36.2\n## 6 0.02985  0  2.18    0 0.458 6.430 58.7 6.0622   3 222    18.7  5.21 28.7\nlinear_reg <- lm(formula = medv ~ lstat, data = df)\nlinear_reg## \n## Call:\n## lm(formula = medv ~ lstat, data = df)\n## \n## Coefficients:\n## (Intercept)        lstat  \n##       34.55        -0.95\nsummary(linear_reg)## \n## Call:\n## lm(formula = medv ~ lstat, data = df)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -15.168  -3.990  -1.318   2.034  24.500 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept) 34.55384    0.56263   61.41   <2e-16 ***\n## lstat       -0.95005    0.03873  -24.53   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 6.216 on 504 degrees of freedom\n## Multiple R-squared:  0.5441, Adjusted R-squared:  0.5432 \n## F-statistic: 601.6 on 1 and 504 DF,  p-value: < 2.2e-16\nggplot(data = df,\n       mapping = aes(x = lstat,\n                     y = medv, \n                     col = medv)) +\n  geom_point() +\n  geom_smooth(method=lm, formula = y ~ x, col=\"red\") +\n  guides(col=\"none\")"},{"path":"linear-regression.html","id":"polynomial-regression","chapter":"3 Linear Regression","heading":"3.3 Polynomial Regression","text":"also possible fit polynomial regression model using poly function, whose first argument variable second degree polynomial.also possible print summary model, using aforementioned summary function.Similarly, can plot polynomial regression model using ggplot2:","code":"\npolynomial_reg <- lm(formula=medv~poly(lstat, 2), data=df)\npolynomial_reg## \n## Call:\n## lm(formula = medv ~ poly(lstat, 2), data = df)\n## \n## Coefficients:\n##     (Intercept)  poly(lstat, 2)1  poly(lstat, 2)2  \n##           22.53          -152.46            64.23\nsummary(polynomial_reg)## \n## Call:\n## lm(formula = medv ~ poly(lstat, 2), data = df)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -15.2834  -3.8313  -0.5295   2.3095  25.4148 \n## \n## Coefficients:\n##                  Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)       22.5328     0.2456   91.76   <2e-16 ***\n## poly(lstat, 2)1 -152.4595     5.5237  -27.60   <2e-16 ***\n## poly(lstat, 2)2   64.2272     5.5237   11.63   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 5.524 on 503 degrees of freedom\n## Multiple R-squared:  0.6407, Adjusted R-squared:  0.6393 \n## F-statistic: 448.5 on 2 and 503 DF,  p-value: < 2.2e-16\nggplot(data = df,\n       mapping = aes(x = lstat,\n                     y = medv, \n                     col = medv)) +\n  geom_point(col=\"red\") +\n  geom_smooth(method=lm, formula = y ~ poly(x, 2), col=\"green\") +\n  guides(col=\"none\")"},{"path":"linear-regression.html","id":"multiple-linear-regression","chapter":"3 Linear Regression","heading":"3.4 Multiple Linear Regression","text":"continue use Boston dataset order predict medv using several predictors rm (average number rooms per house), age (average age houses), lstat (percent households low socioeconomic status).order fit multiple linear regression model using least squares, use lm function. syntax lm(y ∼ x1 + x2 + x3) used fit model three predictors, \\(x_1\\), \\(x_2\\), \\(x_3\\). summary function now outputs regression coefficients predictors.Boston data set contains 12 variables, cumbersome type order perform regression using predictors. Instead, can use following short-hand:","code":"\nlinear_reg <- lm(medv ~ lstat + age, data = df)\nsummary(linear_reg)## \n## Call:\n## lm(formula = medv ~ lstat + age, data = df)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -15.981  -3.978  -1.283   1.968  23.158 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept) 33.22276    0.73085  45.458  < 2e-16 ***\n## lstat       -1.03207    0.04819 -21.416  < 2e-16 ***\n## age          0.03454    0.01223   2.826  0.00491 ** \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 6.173 on 503 degrees of freedom\n## Multiple R-squared:  0.5513, Adjusted R-squared:  0.5495 \n## F-statistic:   309 on 2 and 503 DF,  p-value: < 2.2e-16\nlinear_reg <- lm(medv ~ ., data = df)\nsummary(linear_reg)## \n## Call:\n## lm(formula = medv ~ ., data = df)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -15.1304  -2.7673  -0.5814   1.9414  26.2526 \n## \n## Coefficients:\n##               Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  41.617270   4.936039   8.431 3.79e-16 ***\n## crim         -0.121389   0.033000  -3.678 0.000261 ***\n## zn            0.046963   0.013879   3.384 0.000772 ***\n## indus         0.013468   0.062145   0.217 0.828520    \n## chas          2.839993   0.870007   3.264 0.001173 ** \n## nox         -18.758022   3.851355  -4.870 1.50e-06 ***\n## rm            3.658119   0.420246   8.705  < 2e-16 ***\n## age           0.003611   0.013329   0.271 0.786595    \n## dis          -1.490754   0.201623  -7.394 6.17e-13 ***\n## rad           0.289405   0.066908   4.325 1.84e-05 ***\n## tax          -0.012682   0.003801  -3.337 0.000912 ***\n## ptratio      -0.937533   0.132206  -7.091 4.63e-12 ***\n## lstat        -0.552019   0.050659 -10.897  < 2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 4.798 on 493 degrees of freedom\n## Multiple R-squared:  0.7343, Adjusted R-squared:  0.7278 \n## F-statistic: 113.5 on 12 and 493 DF,  p-value: < 2.2e-16"},{"path":"linear-regression.html","id":"wilkinson-rogers-notation","chapter":"3 Linear Regression","heading":"3.5 Wilkinson-Rogers Notation","text":"feature detailing variables using . placeholder possible R uses Wilkinson Rogers’ (1973) notation, allows us write algebraic formula defines statistical model.\nnotation commonly used R, Python & MATLAB statistical libraries.\ntable symbols helps write formulas represent statistical models appear.","code":""}]
